<source>
  @type tail
  format ltsv
  path /path/to/sample.log
  pos_file /tmp/sample.pos
  tag "sample.log"
</source>

<match sample.log>
  @type timestream

  # Amazon Timestream database name.
  database "sampleDB"

  # Amazon Timestream table name.
  table "sampleTable"

  # AWS region. If not specified, search it from environment variable or aws config file.
  # For more details see https://docs.aws.amazon.com/sdk-for-ruby/v3/api/Aws/TimestreamWrite/Client.html
  # region "us-east-1"

  # <aws_credentials>
  #   access_key_id "XXXXXXXXX"
  #   secret_access_key "XXXXXXXXXX"
  # </aws_credentials>

  # Specify which key should be 'measure'.
  # If not, plugin sends dummy measure and writes all keys and values as dimensions.
  # Dummy measure is as follows:
  #   MeasureName: '-'
  #   MeasureValue: '-'
  #   MeasureValueType: 'VARCHAR'
  #<measure>
  #  name "measureNameXXX"
  #  type "VARCHAR"
  #</measure>

  # 'chunk_limit_records' must be configured less or equal to 100.
  # If not, plugin may fails to write record.
  # For now, Plugin sends records in buffer all at once.
  # However Amazon Timestream currently accepts less or equal to 100 records.
  <buffer>
    chunk_limit_records 100
  </buffer>
</match>